{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_2t</th>\n",
       "      <th>prev_t</th>\n",
       "      <th>Word</th>\n",
       "      <th>next_t</th>\n",
       "      <th>next_2t</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>অস্ট্রেলিয়ার</td>\n",
       "      <td>সিডনির</td>\n",
       "      <td>ম্যাকওয়ারি</td>\n",
       "      <td>1.065212</td>\n",
       "      <td>0.458311</td>\n",
       "      <td>0.658449</td>\n",
       "      <td>0.851267</td>\n",
       "      <td>0.642571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849722</td>\n",
       "      <td>0.269087</td>\n",
       "      <td>0.993979</td>\n",
       "      <td>1.083685</td>\n",
       "      <td>0.264122</td>\n",
       "      <td>0.495053</td>\n",
       "      <td>1.005416</td>\n",
       "      <td>0.740280</td>\n",
       "      <td>0.309153</td>\n",
       "      <td>not event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>অস্ট্রেলিয়ার</td>\n",
       "      <td>সিডনির</td>\n",
       "      <td>ম্যাকওয়ারি</td>\n",
       "      <td>বিশ্ববিদ্যালয়ে</td>\n",
       "      <td>0.655353</td>\n",
       "      <td>0.378614</td>\n",
       "      <td>1.010234</td>\n",
       "      <td>1.037825</td>\n",
       "      <td>0.875950</td>\n",
       "      <td>...</td>\n",
       "      <td>1.119942</td>\n",
       "      <td>1.029344</td>\n",
       "      <td>0.435755</td>\n",
       "      <td>0.952289</td>\n",
       "      <td>1.042146</td>\n",
       "      <td>0.330705</td>\n",
       "      <td>0.763490</td>\n",
       "      <td>0.270210</td>\n",
       "      <td>0.765840</td>\n",
       "      <td>not event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>অস্ট্রেলিয়ার</td>\n",
       "      <td>সিডনির</td>\n",
       "      <td>ম্যাকওয়ারি</td>\n",
       "      <td>বিশ্ববিদ্যালয়ে</td>\n",
       "      <td>বছরের</td>\n",
       "      <td>0.403964</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>0.695190</td>\n",
       "      <td>1.093361</td>\n",
       "      <td>0.808709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699272</td>\n",
       "      <td>0.400624</td>\n",
       "      <td>0.484002</td>\n",
       "      <td>0.664833</td>\n",
       "      <td>0.695255</td>\n",
       "      <td>0.877164</td>\n",
       "      <td>1.135145</td>\n",
       "      <td>1.027893</td>\n",
       "      <td>0.900789</td>\n",
       "      <td>not event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>সিডনির</td>\n",
       "      <td>ম্যাকওয়ারি</td>\n",
       "      <td>বিশ্ববিদ্যালয়ে</td>\n",
       "      <td>বছরের</td>\n",
       "      <td>ফেব্রুয়ারি</td>\n",
       "      <td>0.253766</td>\n",
       "      <td>0.194770</td>\n",
       "      <td>0.442101</td>\n",
       "      <td>0.351051</td>\n",
       "      <td>1.047031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627109</td>\n",
       "      <td>1.099211</td>\n",
       "      <td>0.839023</td>\n",
       "      <td>0.328318</td>\n",
       "      <td>0.502781</td>\n",
       "      <td>0.952639</td>\n",
       "      <td>0.735225</td>\n",
       "      <td>0.538891</td>\n",
       "      <td>0.376244</td>\n",
       "      <td>not event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ম্যাকওয়ারি</td>\n",
       "      <td>বিশ্ববিদ্যালয়ে</td>\n",
       "      <td>বছরের</td>\n",
       "      <td>ফেব্রুয়ারি</td>\n",
       "      <td>সেশনে</td>\n",
       "      <td>1.080591</td>\n",
       "      <td>0.247263</td>\n",
       "      <td>0.783865</td>\n",
       "      <td>1.073056</td>\n",
       "      <td>0.678846</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039573</td>\n",
       "      <td>0.695120</td>\n",
       "      <td>0.567450</td>\n",
       "      <td>0.622855</td>\n",
       "      <td>0.923105</td>\n",
       "      <td>0.547295</td>\n",
       "      <td>0.977882</td>\n",
       "      <td>0.452508</td>\n",
       "      <td>1.117842</td>\n",
       "      <td>not event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>অনুষ্ঠানটি</td>\n",
       "      <td>উপস্থাপনা</td>\n",
       "      <td>স্বাগত</td>\n",
       "      <td>সম্পাদক</td>\n",
       "      <td>খলিলুর</td>\n",
       "      <td>0.373112</td>\n",
       "      <td>0.831647</td>\n",
       "      <td>0.763766</td>\n",
       "      <td>0.397133</td>\n",
       "      <td>0.219678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663314</td>\n",
       "      <td>0.668579</td>\n",
       "      <td>0.310295</td>\n",
       "      <td>1.010063</td>\n",
       "      <td>0.374969</td>\n",
       "      <td>0.675856</td>\n",
       "      <td>0.400098</td>\n",
       "      <td>0.465884</td>\n",
       "      <td>1.136187</td>\n",
       "      <td>not event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>উপস্থাপনা</td>\n",
       "      <td>স্বাগত</td>\n",
       "      <td>সম্পাদক</td>\n",
       "      <td>খলিলুর</td>\n",
       "      <td>পর্বে</td>\n",
       "      <td>0.360619</td>\n",
       "      <td>0.537351</td>\n",
       "      <td>0.509267</td>\n",
       "      <td>1.046646</td>\n",
       "      <td>0.320436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708681</td>\n",
       "      <td>0.681685</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.877110</td>\n",
       "      <td>1.156811</td>\n",
       "      <td>0.585852</td>\n",
       "      <td>0.710907</td>\n",
       "      <td>0.983406</td>\n",
       "      <td>0.656157</td>\n",
       "      <td>not event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>স্বাগত</td>\n",
       "      <td>সম্পাদক</td>\n",
       "      <td>খলিলুর</td>\n",
       "      <td>পর্বে</td>\n",
       "      <td>অনুষ্ঠানে</td>\n",
       "      <td>0.316630</td>\n",
       "      <td>0.266114</td>\n",
       "      <td>1.043380</td>\n",
       "      <td>0.802580</td>\n",
       "      <td>0.794168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908570</td>\n",
       "      <td>1.221956</td>\n",
       "      <td>0.956329</td>\n",
       "      <td>0.545493</td>\n",
       "      <td>0.705635</td>\n",
       "      <td>1.023264</td>\n",
       "      <td>0.778715</td>\n",
       "      <td>0.792393</td>\n",
       "      <td>0.560241</td>\n",
       "      <td>event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>সম্পাদক</td>\n",
       "      <td>খলিলুর</td>\n",
       "      <td>পর্বে</td>\n",
       "      <td>অনুষ্ঠানে</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930987</td>\n",
       "      <td>0.839666</td>\n",
       "      <td>1.087890</td>\n",
       "      <td>0.946772</td>\n",
       "      <td>0.274437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616596</td>\n",
       "      <td>0.557665</td>\n",
       "      <td>0.410402</td>\n",
       "      <td>0.707961</td>\n",
       "      <td>0.222590</td>\n",
       "      <td>0.866323</td>\n",
       "      <td>0.619137</td>\n",
       "      <td>0.674066</td>\n",
       "      <td>0.585274</td>\n",
       "      <td>event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>খলিলুর</td>\n",
       "      <td>পর্বে</td>\n",
       "      <td>অনুষ্ঠানে</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.228666</td>\n",
       "      <td>0.483727</td>\n",
       "      <td>0.738560</td>\n",
       "      <td>0.956385</td>\n",
       "      <td>1.020990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384667</td>\n",
       "      <td>0.890894</td>\n",
       "      <td>0.469062</td>\n",
       "      <td>0.420312</td>\n",
       "      <td>1.157544</td>\n",
       "      <td>0.634191</td>\n",
       "      <td>1.147568</td>\n",
       "      <td>0.312701</td>\n",
       "      <td>0.781165</td>\n",
       "      <td>event</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          prev_2t          prev_t            Word          next_t  \\\n",
       "0             NaN             NaN    অস্ট্রেলিয়ার          সিডনির   \n",
       "1             NaN    অস্ট্রেলিয়ার          সিডনির      ম্যাকওয়ারি   \n",
       "2    অস্ট্রেলিয়ার          সিডনির      ম্যাকওয়ারি  বিশ্ববিদ্যালয়ে   \n",
       "3          সিডনির      ম্যাকওয়ারি  বিশ্ববিদ্যালয়ে           বছরের   \n",
       "4      ম্যাকওয়ারি  বিশ্ববিদ্যালয়ে           বছরের      ফেব্রুয়ারি   \n",
       "..            ...             ...             ...             ...   \n",
       "156    অনুষ্ঠানটি       উপস্থাপনা          স্বাগত         সম্পাদক   \n",
       "157     উপস্থাপনা          স্বাগত         সম্পাদক          খলিলুর   \n",
       "158        স্বাগত         সম্পাদক          খলিলুর           পর্বে   \n",
       "159       সম্পাদক          খলিলুর           পর্বে       অনুষ্ঠানে   \n",
       "160        খলিলুর           পর্বে       অনুষ্ঠানে             NaN   \n",
       "\n",
       "            next_2t         0         1         2         3         4  ...  \\\n",
       "0        ম্যাকওয়ারি  1.065212  0.458311  0.658449  0.851267  0.642571  ...   \n",
       "1    বিশ্ববিদ্যালয়ে  0.655353  0.378614  1.010234  1.037825  0.875950  ...   \n",
       "2             বছরের  0.403964  0.452500  0.695190  1.093361  0.808709  ...   \n",
       "3        ফেব্রুয়ারি  0.253766  0.194770  0.442101  0.351051  1.047031  ...   \n",
       "4             সেশনে  1.080591  0.247263  0.783865  1.073056  0.678846  ...   \n",
       "..              ...       ...       ...       ...       ...       ...  ...   \n",
       "156          খলিলুর  0.373112  0.831647  0.763766  0.397133  0.219678  ...   \n",
       "157           পর্বে  0.360619  0.537351  0.509267  1.046646  0.320436  ...   \n",
       "158       অনুষ্ঠানে  0.316630  0.266114  1.043380  0.802580  0.794168  ...   \n",
       "159             NaN  0.930987  0.839666  1.087890  0.946772  0.274437  ...   \n",
       "160             NaN  0.228666  0.483727  0.738560  0.956385  1.020990  ...   \n",
       "\n",
       "           23        24        25        26        27        28        29  \\\n",
       "0    0.849722  0.269087  0.993979  1.083685  0.264122  0.495053  1.005416   \n",
       "1    1.119942  1.029344  0.435755  0.952289  1.042146  0.330705  0.763490   \n",
       "2    0.699272  0.400624  0.484002  0.664833  0.695255  0.877164  1.135145   \n",
       "3    0.627109  1.099211  0.839023  0.328318  0.502781  0.952639  0.735225   \n",
       "4    1.039573  0.695120  0.567450  0.622855  0.923105  0.547295  0.977882   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "156  0.663314  0.668579  0.310295  1.010063  0.374969  0.675856  0.400098   \n",
       "157  0.708681  0.681685  0.441341  0.877110  1.156811  0.585852  0.710907   \n",
       "158  0.908570  1.221956  0.956329  0.545493  0.705635  1.023264  0.778715   \n",
       "159  0.616596  0.557665  0.410402  0.707961  0.222590  0.866323  0.619137   \n",
       "160  0.384667  0.890894  0.469062  0.420312  1.157544  0.634191  1.147568   \n",
       "\n",
       "           30        31      class  \n",
       "0    0.740280  0.309153  not event  \n",
       "1    0.270210  0.765840  not event  \n",
       "2    1.027893  0.900789  not event  \n",
       "3    0.538891  0.376244  not event  \n",
       "4    0.452508  1.117842  not event  \n",
       "..        ...       ...        ...  \n",
       "156  0.465884  1.136187  not event  \n",
       "157  0.983406  0.656157  not event  \n",
       "158  0.792393  0.560241      event  \n",
       "159  0.674066  0.585274      event  \n",
       "160  0.312701  0.781165      event  \n",
       "\n",
       "[161 rows x 38 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel ('test.xlsx') \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word'] = labelencoder.fit_transform(df['Word'].astype(str))\n",
    "df['prev_t'] = labelencoder.fit_transform(df['prev_t'].astype(str))\n",
    "df['prev_2t'] = labelencoder.fit_transform(df['prev_2t'].astype(str))\n",
    "df['next_t'] = labelencoder.fit_transform(df['next_t'].astype(str))\n",
    "df['next_2t'] = labelencoder.fit_transform(df['next_2t'].astype(str))\n",
    "df['class'] = labelencoder.fit_transform(df['class'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prev_2t</th>\n",
       "      <th>prev_t</th>\n",
       "      <th>Word</th>\n",
       "      <th>next_t</th>\n",
       "      <th>next_2t</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>147</td>\n",
       "      <td>119</td>\n",
       "      <td>1.065212</td>\n",
       "      <td>0.458311</td>\n",
       "      <td>0.658449</td>\n",
       "      <td>0.851267</td>\n",
       "      <td>0.642571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849722</td>\n",
       "      <td>0.269087</td>\n",
       "      <td>0.993979</td>\n",
       "      <td>1.083685</td>\n",
       "      <td>0.264122</td>\n",
       "      <td>0.495053</td>\n",
       "      <td>1.005416</td>\n",
       "      <td>0.740280</td>\n",
       "      <td>0.309153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>147</td>\n",
       "      <td>119</td>\n",
       "      <td>101</td>\n",
       "      <td>0.655353</td>\n",
       "      <td>0.378614</td>\n",
       "      <td>1.010234</td>\n",
       "      <td>1.037825</td>\n",
       "      <td>0.875950</td>\n",
       "      <td>...</td>\n",
       "      <td>1.119942</td>\n",
       "      <td>1.029344</td>\n",
       "      <td>0.435755</td>\n",
       "      <td>0.952289</td>\n",
       "      <td>1.042146</td>\n",
       "      <td>0.330705</td>\n",
       "      <td>0.763490</td>\n",
       "      <td>0.270210</td>\n",
       "      <td>0.765840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>147</td>\n",
       "      <td>119</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>0.403964</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>0.695190</td>\n",
       "      <td>1.093361</td>\n",
       "      <td>0.808709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699272</td>\n",
       "      <td>0.400624</td>\n",
       "      <td>0.484002</td>\n",
       "      <td>0.664833</td>\n",
       "      <td>0.695255</td>\n",
       "      <td>0.877164</td>\n",
       "      <td>1.135145</td>\n",
       "      <td>1.027893</td>\n",
       "      <td>0.900789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>146</td>\n",
       "      <td>119</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>0.253766</td>\n",
       "      <td>0.194770</td>\n",
       "      <td>0.442101</td>\n",
       "      <td>0.351051</td>\n",
       "      <td>1.047031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627109</td>\n",
       "      <td>1.099211</td>\n",
       "      <td>0.839023</td>\n",
       "      <td>0.328318</td>\n",
       "      <td>0.502781</td>\n",
       "      <td>0.952639</td>\n",
       "      <td>0.735225</td>\n",
       "      <td>0.538891</td>\n",
       "      <td>0.376244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>148</td>\n",
       "      <td>1.080591</td>\n",
       "      <td>0.247263</td>\n",
       "      <td>0.783865</td>\n",
       "      <td>1.073056</td>\n",
       "      <td>0.678846</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039573</td>\n",
       "      <td>0.695120</td>\n",
       "      <td>0.567450</td>\n",
       "      <td>0.622855</td>\n",
       "      <td>0.923105</td>\n",
       "      <td>0.547295</td>\n",
       "      <td>0.977882</td>\n",
       "      <td>0.452508</td>\n",
       "      <td>1.117842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>153</td>\n",
       "      <td>141</td>\n",
       "      <td>53</td>\n",
       "      <td>0.373112</td>\n",
       "      <td>0.831647</td>\n",
       "      <td>0.763766</td>\n",
       "      <td>0.397133</td>\n",
       "      <td>0.219678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663314</td>\n",
       "      <td>0.668579</td>\n",
       "      <td>0.310295</td>\n",
       "      <td>1.010063</td>\n",
       "      <td>0.374969</td>\n",
       "      <td>0.675856</td>\n",
       "      <td>0.400098</td>\n",
       "      <td>0.465884</td>\n",
       "      <td>1.136187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>35</td>\n",
       "      <td>153</td>\n",
       "      <td>141</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>0.360619</td>\n",
       "      <td>0.537351</td>\n",
       "      <td>0.509267</td>\n",
       "      <td>1.046646</td>\n",
       "      <td>0.320436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708681</td>\n",
       "      <td>0.681685</td>\n",
       "      <td>0.441341</td>\n",
       "      <td>0.877110</td>\n",
       "      <td>1.156811</td>\n",
       "      <td>0.585852</td>\n",
       "      <td>0.710907</td>\n",
       "      <td>0.983406</td>\n",
       "      <td>0.656157</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>152</td>\n",
       "      <td>141</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316630</td>\n",
       "      <td>0.266114</td>\n",
       "      <td>1.043380</td>\n",
       "      <td>0.802580</td>\n",
       "      <td>0.794168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908570</td>\n",
       "      <td>1.221956</td>\n",
       "      <td>0.956329</td>\n",
       "      <td>0.545493</td>\n",
       "      <td>0.705635</td>\n",
       "      <td>1.023264</td>\n",
       "      <td>0.778715</td>\n",
       "      <td>0.792393</td>\n",
       "      <td>0.560241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>140</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930987</td>\n",
       "      <td>0.839666</td>\n",
       "      <td>1.087890</td>\n",
       "      <td>0.946772</td>\n",
       "      <td>0.274437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616596</td>\n",
       "      <td>0.557665</td>\n",
       "      <td>0.410402</td>\n",
       "      <td>0.707961</td>\n",
       "      <td>0.222590</td>\n",
       "      <td>0.866323</td>\n",
       "      <td>0.619137</td>\n",
       "      <td>0.674066</td>\n",
       "      <td>0.585274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>53</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228666</td>\n",
       "      <td>0.483727</td>\n",
       "      <td>0.738560</td>\n",
       "      <td>0.956385</td>\n",
       "      <td>1.020990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384667</td>\n",
       "      <td>0.890894</td>\n",
       "      <td>0.469062</td>\n",
       "      <td>0.420312</td>\n",
       "      <td>1.157544</td>\n",
       "      <td>0.634191</td>\n",
       "      <td>1.147568</td>\n",
       "      <td>0.312701</td>\n",
       "      <td>0.781165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prev_2t  prev_t  Word  next_t  next_2t         0         1         2  \\\n",
       "0          0       0    10     147      119  1.065212  0.458311  0.658449   \n",
       "1          0      10   147     119      101  0.655353  0.378614  1.010234   \n",
       "2         10     147   119     101       92  0.403964  0.452500  0.695190   \n",
       "3        146     119   101      92       90  0.253766  0.194770  0.442101   \n",
       "4        118     101    92      90      148  1.080591  0.247263  0.783865   \n",
       "..       ...     ...   ...     ...      ...       ...       ...       ...   \n",
       "156        5      35   153     141       53  0.373112  0.831647  0.763766   \n",
       "157       35     153   141      53       75  0.360619  0.537351  0.509267   \n",
       "158      152     141    53      75        7  0.316630  0.266114  1.043380   \n",
       "159      140      53    75       7        0  0.930987  0.839666  1.087890   \n",
       "160       53      75     6       0        0  0.228666  0.483727  0.738560   \n",
       "\n",
       "            3         4  ...        23        24        25        26  \\\n",
       "0    0.851267  0.642571  ...  0.849722  0.269087  0.993979  1.083685   \n",
       "1    1.037825  0.875950  ...  1.119942  1.029344  0.435755  0.952289   \n",
       "2    1.093361  0.808709  ...  0.699272  0.400624  0.484002  0.664833   \n",
       "3    0.351051  1.047031  ...  0.627109  1.099211  0.839023  0.328318   \n",
       "4    1.073056  0.678846  ...  1.039573  0.695120  0.567450  0.622855   \n",
       "..        ...       ...  ...       ...       ...       ...       ...   \n",
       "156  0.397133  0.219678  ...  0.663314  0.668579  0.310295  1.010063   \n",
       "157  1.046646  0.320436  ...  0.708681  0.681685  0.441341  0.877110   \n",
       "158  0.802580  0.794168  ...  0.908570  1.221956  0.956329  0.545493   \n",
       "159  0.946772  0.274437  ...  0.616596  0.557665  0.410402  0.707961   \n",
       "160  0.956385  1.020990  ...  0.384667  0.890894  0.469062  0.420312   \n",
       "\n",
       "           27        28        29        30        31  class  \n",
       "0    0.264122  0.495053  1.005416  0.740280  0.309153      1  \n",
       "1    1.042146  0.330705  0.763490  0.270210  0.765840      1  \n",
       "2    0.695255  0.877164  1.135145  1.027893  0.900789      1  \n",
       "3    0.502781  0.952639  0.735225  0.538891  0.376244      1  \n",
       "4    0.923105  0.547295  0.977882  0.452508  1.117842      1  \n",
       "..        ...       ...       ...       ...       ...    ...  \n",
       "156  0.374969  0.675856  0.400098  0.465884  1.136187      1  \n",
       "157  1.156811  0.585852  0.710907  0.983406  0.656157      1  \n",
       "158  0.705635  1.023264  0.778715  0.792393  0.560241      0  \n",
       "159  0.222590  0.866323  0.619137  0.674066  0.585274      0  \n",
       "160  1.157544  0.634191  1.147568  0.312701  0.781165      0  \n",
       "\n",
       "[161 rows x 38 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:37] \n",
    "Y = df.iloc[:,37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "Name: class, dtype: int32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 for not-event\n",
    "# 0 for event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 10000\n",
    "max_len = 37\n",
    "embedding_mat_columns=128\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_vocab, output_dim=embedding_mat_columns, input_length=max_len))\n",
    "#model.add(GRU(output_dim=128, activation='sigmoid'))\n",
    "model.add(LSTM(units=embedding_mat_columns))\n",
    "#model.add(GRU(units=embedding_mat_columns))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(layers.Dense(100, activation='sigmoid'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adagrad', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 37, 128)           1280000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,424,585\n",
      "Trainable params: 1,424,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 33 samples\n",
      "Epoch 1/100\n",
      "128/128 [==============================] - 3s 25ms/step - loss: 0.7025 - accuracy: 0.5547 - val_loss: 0.6709 - val_accuracy: 0.6061\n",
      "Epoch 2/100\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.6818 - accuracy: 0.6016 - val_loss: 0.6719 - val_accuracy: 0.6061\n",
      "Epoch 3/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6738 - accuracy: 0.6016 - val_loss: 0.6711 - val_accuracy: 0.6061\n",
      "Epoch 4/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.6808 - accuracy: 0.6016 - val_loss: 0.6712 - val_accuracy: 0.6061\n",
      "Epoch 5/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6749 - accuracy: 0.6016 - val_loss: 0.6731 - val_accuracy: 0.6061\n",
      "Epoch 6/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6778 - accuracy: 0.6016 - val_loss: 0.6713 - val_accuracy: 0.6061\n",
      "Epoch 7/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6760 - accuracy: 0.6016 - val_loss: 0.6711 - val_accuracy: 0.6061\n",
      "Epoch 8/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.7109 - accuracy: 0.5859 - val_loss: 0.6759 - val_accuracy: 0.6061\n",
      "Epoch 9/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6803 - accuracy: 0.5859 - val_loss: 0.6828 - val_accuracy: 0.6061\n",
      "Epoch 10/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6991 - accuracy: 0.5234 - val_loss: 0.6714 - val_accuracy: 0.6061\n",
      "Epoch 11/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6837 - accuracy: 0.6016 - val_loss: 0.6788 - val_accuracy: 0.6061\n",
      "Epoch 12/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6859 - accuracy: 0.6016 - val_loss: 0.6697 - val_accuracy: 0.6061\n",
      "Epoch 13/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6772 - accuracy: 0.6016 - val_loss: 0.6792 - val_accuracy: 0.6061\n",
      "Epoch 14/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6817 - accuracy: 0.6016 - val_loss: 0.6734 - val_accuracy: 0.6061\n",
      "Epoch 15/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6822 - accuracy: 0.6094 - val_loss: 0.6710 - val_accuracy: 0.6061\n",
      "Epoch 16/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6729 - accuracy: 0.6172 - val_loss: 0.6709 - val_accuracy: 0.6061\n",
      "Epoch 17/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.6685 - accuracy: 0.6172 - val_loss: 0.6715 - val_accuracy: 0.6061\n",
      "Epoch 18/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6957 - accuracy: 0.6094 - val_loss: 0.6676 - val_accuracy: 0.6061\n",
      "Epoch 19/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.6243 - accuracy: 0.6094 - val_loss: 0.5540 - val_accuracy: 0.6061\n",
      "Epoch 20/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.5686 - accuracy: 0.6875 - val_loss: 0.4583 - val_accuracy: 0.8485\n",
      "Epoch 21/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4958 - accuracy: 0.7500 - val_loss: 0.4045 - val_accuracy: 0.8485\n",
      "Epoch 22/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.4518 - accuracy: 0.7891 - val_loss: 0.3957 - val_accuracy: 0.8788\n",
      "Epoch 23/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3723 - accuracy: 0.8516 - val_loss: 0.3982 - val_accuracy: 0.8788\n",
      "Epoch 24/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3558 - accuracy: 0.8594 - val_loss: 0.3957 - val_accuracy: 0.8788\n",
      "Epoch 25/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3563 - accuracy: 0.8594 - val_loss: 0.4009 - val_accuracy: 0.8788\n",
      "Epoch 26/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3511 - accuracy: 0.8672 - val_loss: 0.4007 - val_accuracy: 0.8788\n",
      "Epoch 27/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3439 - accuracy: 0.8672 - val_loss: 0.3980 - val_accuracy: 0.8788\n",
      "Epoch 28/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3180 - accuracy: 0.8750 - val_loss: 0.4095 - val_accuracy: 0.8788\n",
      "Epoch 29/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3219 - accuracy: 0.8750 - val_loss: 0.4111 - val_accuracy: 0.8788\n",
      "Epoch 30/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3162 - accuracy: 0.8750 - val_loss: 0.4178 - val_accuracy: 0.8788\n",
      "Epoch 31/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3180 - accuracy: 0.8750 - val_loss: 0.4190 - val_accuracy: 0.8788\n",
      "Epoch 32/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3148 - accuracy: 0.8750 - val_loss: 0.4195 - val_accuracy: 0.8788\n",
      "Epoch 33/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3163 - accuracy: 0.8750 - val_loss: 0.4217 - val_accuracy: 0.8788\n",
      "Epoch 34/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3164 - accuracy: 0.8750 - val_loss: 0.4221 - val_accuracy: 0.8788\n",
      "Epoch 35/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3043 - accuracy: 0.8828 - val_loss: 0.4247 - val_accuracy: 0.8788\n",
      "Epoch 36/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3037 - accuracy: 0.8828 - val_loss: 0.4267 - val_accuracy: 0.8788\n",
      "Epoch 37/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3048 - accuracy: 0.8828 - val_loss: 0.4275 - val_accuracy: 0.8788\n",
      "Epoch 38/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3031 - accuracy: 0.8828 - val_loss: 0.4265 - val_accuracy: 0.8788\n",
      "Epoch 39/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3036 - accuracy: 0.8828 - val_loss: 0.4264 - val_accuracy: 0.8788\n",
      "Epoch 40/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3029 - accuracy: 0.8828 - val_loss: 0.4271 - val_accuracy: 0.8788\n",
      "Epoch 41/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.2899 - accuracy: 0.8906 - val_loss: 0.4264 - val_accuracy: 0.8788\n",
      "Epoch 42/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.2916 - accuracy: 0.8906 - val_loss: 0.4263 - val_accuracy: 0.8788\n",
      "Epoch 43/100\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.2909 - accuracy: 0.8906 - val_loss: 0.4258 - val_accuracy: 0.8788\n",
      "Epoch 44/100\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.2899 - accuracy: 0.8906 - val_loss: 0.4276 - val_accuracy: 0.8788\n",
      "Epoch 45/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2902 - accuracy: 0.8906 - val_loss: 0.4275 - val_accuracy: 0.8788\n",
      "Epoch 46/100\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.2904 - accuracy: 0.8906 - val_loss: 0.4290 - val_accuracy: 0.8788\n",
      "Epoch 47/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2909 - accuracy: 0.8906 - val_loss: 0.4297 - val_accuracy: 0.8788\n",
      "Epoch 48/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2902 - accuracy: 0.8906 - val_loss: 0.4276 - val_accuracy: 0.8788\n",
      "Epoch 49/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2939 - accuracy: 0.8906 - val_loss: 0.4279 - val_accuracy: 0.8788\n",
      "Epoch 50/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2798 - accuracy: 0.8984 - val_loss: 0.4281 - val_accuracy: 0.8788\n",
      "Epoch 51/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2767 - accuracy: 0.8984 - val_loss: 0.4275 - val_accuracy: 0.8788\n",
      "Epoch 52/100\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.2783 - accuracy: 0.8984 - val_loss: 0.4276 - val_accuracy: 0.8788\n",
      "Epoch 53/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2776 - accuracy: 0.8984 - val_loss: 0.4270 - val_accuracy: 0.8788\n",
      "Epoch 54/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2798 - accuracy: 0.8984 - val_loss: 0.4273 - val_accuracy: 0.8788\n",
      "Epoch 55/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2792 - accuracy: 0.8984 - val_loss: 0.4272 - val_accuracy: 0.8788\n",
      "Epoch 56/100\n",
      "128/128 [==============================] - 1s 10ms/step - loss: 0.2791 - accuracy: 0.8984 - val_loss: 0.4271 - val_accuracy: 0.8788\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 1s 8ms/step - loss: 0.2774 - accuracy: 0.8984 - val_loss: 0.4275 - val_accuracy: 0.8788\n",
      "Epoch 58/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2773 - accuracy: 0.8984 - val_loss: 0.4253 - val_accuracy: 0.8788\n",
      "Epoch 59/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2773 - accuracy: 0.8984 - val_loss: 0.4247 - val_accuracy: 0.8788\n",
      "Epoch 60/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2771 - accuracy: 0.8984 - val_loss: 0.4242 - val_accuracy: 0.8788\n",
      "Epoch 61/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2818 - accuracy: 0.8984 - val_loss: 0.4241 - val_accuracy: 0.8788\n",
      "Epoch 62/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2787 - accuracy: 0.8984 - val_loss: 0.4245 - val_accuracy: 0.8788\n",
      "Epoch 63/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2774 - accuracy: 0.8984 - val_loss: 0.4237 - val_accuracy: 0.8788\n",
      "Epoch 64/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2773 - accuracy: 0.8984 - val_loss: 0.4237 - val_accuracy: 0.8788\n",
      "Epoch 65/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2769 - accuracy: 0.8984 - val_loss: 0.4239 - val_accuracy: 0.8788\n",
      "Epoch 66/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2766 - accuracy: 0.8984 - val_loss: 0.4223 - val_accuracy: 0.8788\n",
      "Epoch 67/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2767 - accuracy: 0.8984 - val_loss: 0.4226 - val_accuracy: 0.8788\n",
      "Epoch 68/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2764 - accuracy: 0.8984 - val_loss: 0.4236 - val_accuracy: 0.8788\n",
      "Epoch 69/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2767 - accuracy: 0.8984 - val_loss: 0.4234 - val_accuracy: 0.8788\n",
      "Epoch 70/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2785 - accuracy: 0.8984 - val_loss: 0.4233 - val_accuracy: 0.8788\n",
      "Epoch 71/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2766 - accuracy: 0.8984 - val_loss: 0.4235 - val_accuracy: 0.8788\n",
      "Epoch 72/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2764 - accuracy: 0.8984 - val_loss: 0.4237 - val_accuracy: 0.8788\n",
      "Epoch 73/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2513 - accuracy: 0.9141 - val_loss: 0.4235 - val_accuracy: 0.8788\n",
      "Epoch 74/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2506 - accuracy: 0.9141 - val_loss: 0.4233 - val_accuracy: 0.8788\n",
      "Epoch 75/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2507 - accuracy: 0.9141 - val_loss: 0.4232 - val_accuracy: 0.8788\n",
      "Epoch 76/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2522 - accuracy: 0.9141 - val_loss: 0.4235 - val_accuracy: 0.8788\n",
      "Epoch 77/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2524 - accuracy: 0.9141 - val_loss: 0.4232 - val_accuracy: 0.8788\n",
      "Epoch 78/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2511 - accuracy: 0.9141 - val_loss: 0.4229 - val_accuracy: 0.8788\n",
      "Epoch 79/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2504 - accuracy: 0.9141 - val_loss: 0.4226 - val_accuracy: 0.8788\n",
      "Epoch 80/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2511 - accuracy: 0.9141 - val_loss: 0.4226 - val_accuracy: 0.8788\n",
      "Epoch 81/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2508 - accuracy: 0.9141 - val_loss: 0.4226 - val_accuracy: 0.8788\n",
      "Epoch 82/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2510 - accuracy: 0.9141 - val_loss: 0.4225 - val_accuracy: 0.8788\n",
      "Epoch 83/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2511 - accuracy: 0.9141 - val_loss: 0.4223 - val_accuracy: 0.8788\n",
      "Epoch 84/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.2503 - accuracy: 0.9141 - val_loss: 0.4225 - val_accuracy: 0.8788\n",
      "Epoch 85/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2505 - accuracy: 0.9141 - val_loss: 0.4229 - val_accuracy: 0.8788\n",
      "Epoch 86/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2501 - accuracy: 0.9141 - val_loss: 0.4229 - val_accuracy: 0.8788\n",
      "Epoch 87/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.2518 - accuracy: 0.9141 - val_loss: 0.4225 - val_accuracy: 0.8788\n",
      "Epoch 88/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2504 - accuracy: 0.9141 - val_loss: 0.4224 - val_accuracy: 0.8788\n",
      "Epoch 89/100\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.2500 - accuracy: 0.9141 - val_loss: 0.4205 - val_accuracy: 0.8788\n",
      "Epoch 90/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2506 - accuracy: 0.9141 - val_loss: 0.4206 - val_accuracy: 0.8788\n",
      "Epoch 91/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2499 - accuracy: 0.9141 - val_loss: 0.4207 - val_accuracy: 0.8788\n",
      "Epoch 92/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2497 - accuracy: 0.9141 - val_loss: 0.4189 - val_accuracy: 0.8788\n",
      "Epoch 93/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2493 - accuracy: 0.9141 - val_loss: 0.4191 - val_accuracy: 0.8788\n",
      "Epoch 94/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2496 - accuracy: 0.9141 - val_loss: 0.4195 - val_accuracy: 0.8788\n",
      "Epoch 95/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2491 - accuracy: 0.9141 - val_loss: 0.4196 - val_accuracy: 0.8788\n",
      "Epoch 96/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2496 - accuracy: 0.9141 - val_loss: 0.4195 - val_accuracy: 0.8788\n",
      "Epoch 97/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2488 - accuracy: 0.9141 - val_loss: 0.4180 - val_accuracy: 0.8788\n",
      "Epoch 98/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2505 - accuracy: 0.9141 - val_loss: 0.4178 - val_accuracy: 0.8788\n",
      "Epoch 99/100\n",
      "128/128 [==============================] - 1s 9ms/step - loss: 0.2512 - accuracy: 0.9141 - val_loss: 0.4186 - val_accuracy: 0.8788\n",
      "Epoch 100/100\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2503 - accuracy: 0.9141 - val_loss: 0.4187 - val_accuracy: 0.8788\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 586us/step\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.41%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2472224161028862, 0.9140625]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 873us/step\n",
      "Test loss is 0.42 accuracy is 0.88 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        13\n",
      "           1       0.90      0.90      0.90        20\n",
      "\n",
      "    accuracy                           0.88        33\n",
      "   macro avg       0.87      0.87      0.87        33\n",
      "weighted avg       0.88      0.88      0.88        33\n",
      "\n",
      "[[11  2]\n",
      " [ 2 18]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "pred = model.predict_classes(X_test)\n",
    "acc = model.evaluate(X_test, Y_test)\n",
    "print(\"Test loss is {0:.2f} accuracy is {1:.2f} \".format(acc[0],acc[1]))\n",
    "print(classification_report(pred,Y_test))\n",
    "print(confusion_matrix(pred,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pyplot.subplot(211)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
